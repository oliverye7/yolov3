{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv3 Project\n",
    "\n",
    "> This was a mini personal project to explore YOLOv3, an object detection algorithm. I was pretty into object detection for a bit in sophomore year, so I decided to just go full send down the rabbit hole -- I started with sliding window, explored CNNs, various transfer learning techniques, and ended up wanting to run object detection with video. Reading the YOLOv3 paper and watching Youtubers explain how the algorithm worked was my motivation for making this notebook; I basically read the paper and thought it was really cool so I decided to implement it.\n",
    "\n",
    "> Recently I did the same thing with GPT models; after reading the self attention paper, I implemented a miniGPT that can babble infinite Shakespeare (heavily inspired by Andrew Karpathy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import gdown\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers import concatenate, add\n",
    "from keras.models import Model\n",
    "import struct\n",
    "import cv2\n",
    "from copy import deepcopy\n",
    "\n",
    "# Prepare data\n",
    "DATA_ROOT = '/content/data'\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "\n",
    "image_url = 'https://drive.google.com/uc?id=12ZpZ5H0kJIkWk6y4ktGfqR5OTKofL7qw'\n",
    "image_path = os.path.join(DATA_ROOT, 'image.jpg')\n",
    "gdown.download(image_url, image_path, True)\n",
    "\n",
    "image2_url = 'https://drive.google.com/uc?id=1_WpFbGEuS2r19UeP6wekbcF0kb-0nH18'\n",
    "image2_path = os.path.join(DATA_ROOT, 'image2.jpg')\n",
    "gdown.download(image2_url, image2_path, True)\n",
    "\n",
    "video_url = 'https://drive.google.com/uc?id=1xFGjpzhZVYtNor9hJevvxysGESZJIMDz'\n",
    "video_path = os.path.join(DATA_ROOT, 'video1.mp4')\n",
    "gdown.download(video_url, video_path, True)\n",
    "\n",
    "model_url = 'https://drive.google.com/uc?id=19XKJWMKDfDlag2MR8ofjwvxhtr9BxqqN'\n",
    "model_path = os.path.join(DATA_ROOT, 'yolo_weights.h5')\n",
    "gdown.download(model_url, model_path, True)\n",
    "\n",
    "\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
    "              \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
    "              \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
    "              \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
    "              \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
    "              \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
    "              \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
    "              \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
    "              \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
    "              \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bounding box class\n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "\n",
    "        return self.score\n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "             return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "\n",
    "    intersect = intersect_w * intersect_h\n",
    "\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "\n",
    "    return float(intersect) / union\n",
    "\n",
    "\n",
    "def decode_netout(netout_, obj_thresh, anchors_, image_h, image_w, net_h, net_w):\n",
    "    netout_all = deepcopy(netout_)\n",
    "    boxes_all = []\n",
    "    for i in range(len(netout_all)):\n",
    "      netout = netout_all[i][0]\n",
    "      anchors = anchors_[i]\n",
    "\n",
    "      grid_h, grid_w = netout.shape[:2]\n",
    "      nb_box = 3\n",
    "      netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "      nb_class = netout.shape[-1] - 5\n",
    "\n",
    "      boxes = []\n",
    "\n",
    "      netout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "      netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "      netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "      netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "      for i in range(grid_h*grid_w):\n",
    "          row = i // grid_w\n",
    "          col = i % grid_w\n",
    "\n",
    "          for b in range(nb_box):\n",
    "              # 4th element is objectness score\n",
    "              objectness = netout[row][col][b][4]\n",
    "              #objectness = netout[..., :4]\n",
    "              # last elements are class probabilities\n",
    "              classes = netout[row][col][b][5:]\n",
    "\n",
    "              if((classes <= obj_thresh).all()): continue\n",
    "\n",
    "              # first 4 elements are x, y, w, and h\n",
    "              x, y, w, h = netout[row][col][b][:4]\n",
    "\n",
    "              x = (col + x) / grid_w # center position, unit: image width\n",
    "              y = (row + y) / grid_h # center position, unit: image height\n",
    "              w = anchors[b][0] * np.exp(w) / net_w # unit: image width\n",
    "              h = anchors[b][1] * np.exp(h) / net_h # unit: image height\n",
    "\n",
    "              box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "              #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
    "\n",
    "              boxes.append(box)\n",
    "\n",
    "      boxes_all += boxes\n",
    "\n",
    "    # Correct boxes\n",
    "    boxes_all = correct_yolo_boxes(boxes_all, image_h, image_w, net_h, net_w)\n",
    "\n",
    "    return boxes_all\n",
    "\n",
    "def correct_yolo_boxes(boxes_, image_h, image_w, net_h, net_w):\n",
    "    boxes = deepcopy(boxes_)\n",
    "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
    "        new_w = net_w\n",
    "        new_h = (image_h*net_w)/image_w\n",
    "    else:\n",
    "        new_h = net_w\n",
    "        new_w = (image_w*net_h)/image_h\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "\n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "    return boxes\n",
    "\n",
    "def do_nms(boxes_, nms_thresh, obj_thresh):\n",
    "    boxes = deepcopy(boxes_)\n",
    "    if len(boxes) > 0:\n",
    "        num_class = len(boxes[0].classes)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    for c in range(num_class):\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "\n",
    "            if boxes[index_i].classes[c] == 0: continue\n",
    "\n",
    "            for j in range(i+1, len(sorted_indices)):\n",
    "                index_j = sorted_indices[j]\n",
    "\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "                    boxes[index_j].classes[c] = 0\n",
    "\n",
    "    new_boxes = []\n",
    "    for box in boxes:\n",
    "        label = -1\n",
    "\n",
    "        for i in range(num_class):\n",
    "            if box.classes[i] > obj_thresh:\n",
    "                label = i\n",
    "                # print(\"{}: {}, ({}, {})\".format(labels[i], box.classes[i]*100, box.xmin, box.ymin))\n",
    "                box.label = label\n",
    "                box.score = box.classes[i]\n",
    "                new_boxes.append(box)\n",
    "\n",
    "    return new_boxes\n",
    "\n",
    "\n",
    "from PIL import ImageDraw, ImageFont\n",
    "import colorsys\n",
    "\n",
    "def draw_boxes(image_, boxes, labels):\n",
    "    image = image_.copy()\n",
    "    image_w, image_h = image.size\n",
    "    font = ImageFont.truetype(font='/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf',\n",
    "                    size=np.floor(3e-2 * image_h + 0.5).astype('int32'))\n",
    "    thickness = (image_w + image_h) // 300\n",
    "\n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    hsv_tuples = [(x / len(labels), 1., 1.)\n",
    "                  for x in range(len(labels))]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(\n",
    "        map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "    np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "    np.random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "    np.random.seed(None)  # Reset seed to default.\n",
    "\n",
    "    for i, box in reversed(list(enumerate(boxes))):\n",
    "        c = box.get_label()\n",
    "        predicted_class = labels[c]\n",
    "        score = box.get_score()\n",
    "        top, left, bottom, right = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        label_size = draw.textbbox((0,0),label, font)\n",
    "        label_size = (label_size[2], label_size[3])\n",
    "\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image_h, np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image_w, np.floor(right + 0.5).astype('int32'))\n",
    "        print(label, (left, top), (right, bottom))\n",
    "\n",
    "        if top - label_size[1] >= 0:\n",
    "            text_origin = np.array([left, top - label_size[1]])\n",
    "        else:\n",
    "            text_origin = np.array([left, top + 1])\n",
    "\n",
    "        for i in range(thickness):\n",
    "            draw.rectangle(\n",
    "                [left + i, top + i, right - i, bottom - i],\n",
    "                outline=colors[c])\n",
    "        draw.rectangle(\n",
    "            [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "            fill=colors[c])\n",
    "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "        #draw.text(text_origin, label, fill=(0, 0, 0))\n",
    "        del draw\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/oliver/Code/Python/YOLOv3.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/oliver/Code/Python/YOLOv3.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oliver/Code/Python/YOLOv3.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m device_name \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mtest\u001b[39m.\u001b[39mgpu_device_name()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oliver/Code/Python/YOLOv3.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mif\u001b[39;00m device_name \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/device:GPU:0\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = [[[116,90], [156,198], [373,326]], [[30,61], [62,45], [59,119]], [[10,13], [16,30], [33,23]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import  pyplot as plt\n",
    "\n",
    "image_path = '/content/data/image.jpg'\n",
    "\n",
    "image_pil = Image.open(image_path)\n",
    "image_w, image_h = image_pil.size\n",
    "print(\"The type of the saved image is {}\".format(type(image_pil)))\n",
    "plt.imshow(image_pil)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(image_pil, net_h, net_w):\n",
    "    image = np.asarray(image_pil)\n",
    "    new_h, new_w, _ = image.shape\n",
    "    # print(\"net:\", net_h, net_w)\n",
    "    # print(\"old:\",new_h, new_w)\n",
    "    # determine the new size of the image\n",
    "    if (float(net_w)/new_w) < (float(net_h)/new_h):\n",
    "        new_h = (new_h * net_w)/new_w\n",
    "        new_w = net_w\n",
    "    else:\n",
    "        new_w = (new_w * net_h)/new_h\n",
    "        new_h = net_h\n",
    "    new_w = int(new_w)\n",
    "    new_h = int(new_h)\n",
    "    # print(\"new:\",int(new_h), int(new_w))\n",
    "    # resize the image to the new size\n",
    "    #resized = cv2.resize(image[:,:,::-1]/255., (int(new_w), int(new_h)))\n",
    "    resized = cv2.resize(image/255., (int(new_w), int(new_h)))\n",
    "\n",
    "    # embed the image into the standard letter box\n",
    "    # print(\"dims:\",int((net_h-new_h)//2), int((net_h+new_h)//2), int((net_w-new_w)//2), int((net_w+new_w)//2))\n",
    "    new_image = np.ones((net_h, net_w, 3)) * 0.5\n",
    "    new_image[int((net_h-new_h)//2):int((net_h+new_h)//2), int((net_w-new_w)//2):int((net_w+new_w)//2), :] = resized\n",
    "    new_image = np.expand_dims(new_image, 0)\n",
    "    # print(new_image.shape)\n",
    "\n",
    "\n",
    "    return new_image\n",
    "\n",
    "\n",
    "net_h, net_w = 416, 416\n",
    "new_image = preprocess_input(image_pil, net_h, net_w)\n",
    "plt.imshow(new_image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call pretrained yolov3 model with weights using tf.keras [note: i actually read the yolov3 paper and did the math out, didn't just blindly call the function here :)]\n",
    "darknet = tf.keras.models.load_model(model_path)\n",
    "yolo_outputs = darknet.predict(new_image)\n",
    "\n",
    "# bounding box post processing\n",
    "obj_thresh = 0.4\n",
    "nms_thresh = 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = decode_netout(yolo_outputs, obj_thresh, anchors, image_h, image_w, net_h, net_w)\n",
    "boxes = do_nms(boxes, nms_thresh, obj_thresh)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(draw_boxes(image_pil, boxes, labels))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image(image_pil, obj_thresh = 0.4, nms_thresh = 0.45, darknet=darknet, net_h=416, net_w=416, anchors=anchors, labels=labels):\n",
    "  image_w, image_h = image_pil.size\n",
    "  new_image = preprocess_input(image_pil, net_h, net_w)\n",
    "  yolo_outputs = darknet.predict(new_image)\n",
    "  boxes = decode_netout(yolo_outputs, obj_thresh, anchors, image_h, image_w, net_h, net_w)\n",
    "  boxes = do_nms(boxes, nms_thresh, obj_thresh)\n",
    "  image_detect = draw_boxes(image_pil, boxes, labels)\n",
    "\n",
    "  return image_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run detection on videos\n",
    "import cv2\n",
    "\n",
    "def detect_video(video_path, output_path, obj_thresh = 0.4, nms_thresh = 0.45, darknet=darknet, net_h=416, net_w=416, anchors=anchors, labels=labels):\n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "    if not vid.isOpened():\n",
    "        raise IOError(\"Couldn't open webcam or video\")\n",
    "    video_FourCC = int(vid.get(cv2.CAP_PROP_FOURCC))\n",
    "    video_FourCC = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "    video_size = (int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "                        int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, video_FourCC, video_fps, video_size)\n",
    "\n",
    "    num_frame = 0\n",
    "    while vid.isOpened():\n",
    "      ret, frame = vid.read()\n",
    "      num_frame += 1\n",
    "      #print(\"=== Frame {} ===\".format(num_frame))\n",
    "      if ret:\n",
    "          frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "          image = Image.fromarray(frame)\n",
    "          result = detect_image(image)\n",
    "          new_frame = np.asarray(result)\n",
    "          new_frame = cv2.cvtColor(new_frame, cv2.COLOR_RGB2BGR)\n",
    "          out.write(new_frame)\n",
    "      else:\n",
    "          break\n",
    "    vid.release()\n",
    "    out.release()\n",
    "    print(\"New video saved!\")\n",
    "\n",
    "# debugging\n",
    "#vid = cv2.VideoCapture('/content/data/video1.mp4')\n",
    "#h = int(vid.get(cv2.CAP_PROP_FOURCC))\n",
    "#codec = chr(h&0xff) + chr((h>>8)&0xff) + chr((h>>16)&0xff) + chr((h>>24)&0xff)\n",
    "#print(codec)\n",
    "\n",
    "video_path = '/content/data/video1.mp4'\n",
    "output_path = '/content/data/video1_detected.mp4'\n",
    "detect_video(video_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
